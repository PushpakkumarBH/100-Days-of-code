{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwriting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PushpakkumarBH/100-days-of-code/blob/main/Handwriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "sW2nwSBQlpJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "CsaICG3glUPC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "seed(888)\n",
        "tf.random.set_seed(404)\n",
        "from time import strftime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "PliTZBDbl8BA"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "YKT5F4Somysg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_TRAIN_PATH = \"/content/digit_xtrain.csv\"\n",
        "X_TEST_PATH = \"/content/digit_xtest.csv\"\n",
        "Y_TRAIN_PATH = \"/content/digit_ytrain.csv\"\n",
        "Y_TEST_PATH = \"/content/digit_ytest.csv\"\n",
        "LOGGING_PATH = 'tensorboard_mnist_digit_logs/'\n",
        "NR_CLASSES = 10\n",
        "VALIDATION_SIZE = 10000\n",
        "IMAGE_WIDTH = 28\n",
        "IMAGE_HEIGHT = 28\n",
        "CHANNELS = 1\n",
        "TOTAL_INPUTS = IMAGE_WIDTH*IMAGE_HEIGHT*CHANNELS"
      ],
      "metadata": {
        "id": "rrhwTAi4m0dn"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GET THE DATA\n"
      ],
      "metadata": {
        "id": "0ieD36pNnulz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "% time\n",
        "y_train_all = np.loadtxt(Y_TRAIN_PATH,delimiter=',',dtype=int)\n",
        "y_test = np.loadtxt(Y_TEST_PATH,delimiter=',',dtype=int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac6HLEWKnwik",
        "outputId": "ad686e97-7013-4204-b4d4-1baa34feefb0"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25 µs, sys: 0 ns, total: 25 µs\n",
            "Wall time: 30.3 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_all = np.genfromtxt(X_TRAIN_PATH,delimiter=',',dtype=int)\n",
        "x_test = np.loadtxt(X_TEST_PATH,delimiter=',',dtype=int)"
      ],
      "metadata": {
        "id": "w1NAjUOroLPG"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_all.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnFrEAmFockE",
        "outputId": "37b036a2-bdd1-46ef-f178-19e83e8eca3d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_all[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58e4EGKOzg4Y",
        "outputId": "c68d73f6-277f-4e03-da58-4284183be745"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "FQcoQt50zP4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rescale\n",
        "x_train_all, x_test_all = x_train_all/255.0 , x_test_all/255.0"
      ],
      "metadata": {
        "id": "rK5_AXeXqQmR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### one hot encoding"
      ],
      "metadata": {
        "id": "5vftogZg4FKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_all = np.eye(10)[y_train_all]"
      ],
      "metadata": {
        "id": "RheZx874zDCl"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_all = np.eye(10)[y_test_all]"
      ],
      "metadata": {
        "id": "y07vESVO4PQP"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Validation dataset from training data"
      ],
      "metadata": {
        "id": "xY7wgtD54f5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = x_train_all[:VALIDATION_SIZE]\n",
        "y_val = y_train_all[:VALIDATION_SIZE]\n",
        "x_train = x_train_all[:VALIDATION_SIZE:]\n",
        "y_train = y_train_all[:VALIDATION_SIZE]"
      ],
      "metadata": {
        "id": "VmwjTkMR4Z_G"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Tensorflow Graph"
      ],
      "metadata": {
        "id": "RP4MJ5jZEGoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.compat.v1.placeholder(shape=[None, 2], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "3LlXgDOfFasE"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32,shape=[None,784])"
      ],
      "metadata": {
        "id": "ct2z6zapEFsT"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = tf.placeholder(tf.float32,shape=[None,10])"
      ],
      "metadata": {
        "id": "DGXyTZRs5xTG"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Architecture "
      ],
      "metadata": {
        "id": "BAiQYmP4FxA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "BrKJt5XbF2aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nr_epochs=5\n",
        "learning_rate = 1e-4\n",
        "n_hidden1=512\n",
        "n_hidden2=64"
      ],
      "metadata": {
        "id": "KuBSb_y9FrBa"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_w1 = tf.truncated_normal(shape=[738,n_hidden1],stddev=0.1,seed=42)\n",
        "w1 = tf.Variable(initial_value=initial_w1)"
      ],
      "metadata": {
        "id": "zkVGQ0elGMiR"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_b1 = tf.constant(value=0.0,shape=[n_hidden1])\n",
        "b1=tf.Variable(initial_value=initial_b1)"
      ],
      "metadata": {
        "id": "u26bMxsRGNqc"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1_in = matmul()"
      ],
      "metadata": {
        "id": "r8gA00uxKVeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_layer(input, weight_dim, bias_dim, name):\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "        initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
        "        w = tf.Variable(initial_value=initial_w, name='W')\n",
        "\n",
        "        initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
        "        b = tf.Variable(initial_value=initial_b, name='B')\n",
        "\n",
        "        layer_in = tf.matmul(input, w) + b\n",
        "        \n",
        "        if name=='out':\n",
        "            layer_out = tf.nn.softmax(layer_in)\n",
        "        else:\n",
        "            layer_out = tf.nn.relu(layer_in)\n",
        "        \n",
        "        tf.summary.histogram('weights', w)\n",
        "        tf.summary.histogram('biases', b)\n",
        "        \n",
        "        return layer_out"
      ],
      "metadata": {
        "id": "1mZLdb8kLL13"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model without dropout\n",
        "# layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1], \n",
        "#                       bias_dim=[n_hidden1], name='layer_1')\n",
        "\n",
        "# layer_2 = setup_layer(layer_1, weight_dim=[n_hidden1, n_hidden2], \n",
        "#                       bias_dim=[n_hidden2], name='layer_2')\n",
        "\n",
        "# output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES], \n",
        "#                       bias_dim=[NR_CLASSES], name='out')\n",
        "\n",
        "# model_name = f'{n_hidden1}-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
      ],
      "metadata": {
        "id": "HLWJMGo9LjIE"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1], \n",
        "                      bias_dim=[n_hidden1], name='layer_1')\n",
        "\n",
        "layer_drop = tf.nn.dropout(layer_1, keep_prob=0.8, name='dropout_layer')\n",
        "\n",
        "layer_2 = setup_layer(layer_drop, weight_dim=[n_hidden1, n_hidden2], \n",
        "                      bias_dim=[n_hidden2], name='layer_2')\n",
        "\n",
        "output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES], \n",
        "                      bias_dim=[NR_CLASSES], name='out')\n",
        "\n",
        "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
      ],
      "metadata": {
        "id": "Vt0QBjSGLk01"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard Setup"
      ],
      "metadata": {
        "id": "rqvS2BY7LrMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder for Tensorboard\n",
        "\n",
        "folder_name = f'{model_name} at {strftime(\"%H:%M\")}'\n",
        "directory = os.path.join(LOGGING_PATH, folder_name)\n",
        "\n",
        "try:\n",
        "    os.makedirs(directory)\n",
        "except OSError as exception:\n",
        "    print(exception.strerror)\n",
        "else:\n",
        "    print('Successfully created directories!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVD9mS4gLn-P",
        "outputId": "ff69cd47-d468-4e0c-e072-1f1f38e0c46f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created directories!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss, Optimisation & Metrics"
      ],
      "metadata": {
        "id": "7L4DBe_CM95r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Loss Function"
      ],
      "metadata": {
        "id": "RDyLjZQ2NBUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('loss_calc'):\n",
        "    loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))"
      ],
      "metadata": {
        "id": "hlfdvPQ-Lyeo"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Optimizer"
      ],
      "metadata": {
        "id": "V3c5IBF6N6d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
        "    train_step = optimizer.minimize(loss)"
      ],
      "metadata": {
        "id": "ynobro7nNGfq"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy Metric"
      ],
      "metadata": {
        "id": "OlomQtK2OKYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('accuracy_calc'):\n",
        "    correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "metadata": {
        "id": "IY1DXeQ9N9-t"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('performance'):\n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "    tf.summary.scalar('cost', loss)"
      ],
      "metadata": {
        "id": "XrkyIbL5ONkv"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Input Images in Tensorboard"
      ],
      "metadata": {
        "id": "CIxk-joFOS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('show_image'):\n",
        "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
        "    tf.summary.image('image_input', x_image, max_outputs=4)"
      ],
      "metadata": {
        "id": "clyAkg3JOQU6"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Session"
      ],
      "metadata": {
        "id": "-Sj4Ex-HOYE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.compat.v1.Session()"
      ],
      "metadata": {
        "id": "GdbNgOv_OVuY"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup Filewriter and Merge Summaries"
      ],
      "metadata": {
        "id": "MCaAxJHDOmd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_summary = tf.compat.v1.summary.merge_all()\n",
        "\n",
        "train_writer = tf.compat.v1.summary.FileWriter(directory + '/train')\n",
        "train_writer.add_graph(sess.graph)\n",
        "\n",
        "validation_writer = tf.compat.v1.summary.FileWriter(directory + '/validation')"
      ],
      "metadata": {
        "id": "9WpfzvJrOane"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialise all the variables"
      ],
      "metadata": {
        "id": "m5iaW3VmPCqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init = tf.compat.v1.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "kXrx8MzlPDd1"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching the Data"
      ],
      "metadata": {
        "id": "8zC3NKedPPL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_batch = 1000"
      ],
      "metadata": {
        "id": "oT1vY_NrPIqH"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = y_train.shape[0]\n",
        "nr_iterations = int(num_examples/size_of_batch)\n",
        "\n",
        "index_in_epoch = 0"
      ],
      "metadata": {
        "id": "RBWK8v8CPSa6"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_batch(batch_size, data, labels):\n",
        "    \n",
        "    global num_examples\n",
        "    global index_in_epoch\n",
        "    \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size\n",
        "    \n",
        "    if index_in_epoch > num_examples:\n",
        "        start = 0\n",
        "        index_in_epoch = batch_size\n",
        "    \n",
        "    end = index_in_epoch\n",
        "    \n",
        "    return data[start:end], labels[start:end]"
      ],
      "metadata": {
        "id": "TKpMPXYUPUeV"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "7IXOvuKkPbe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(nr_epochs):\n",
        "    \n",
        "    # ============= Training Dataset =========\n",
        "    for i in range(nr_iterations):\n",
        "        \n",
        "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_train, labels=y_train)\n",
        "        \n",
        "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
        "        \n",
        "        sess.run(train_step, feed_dict=feed_dictionary)\n",
        "        \n",
        "    \n",
        "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict=feed_dictionary)\n",
        "        \n",
        "    train_writer.add_summary(s, epoch)\n",
        "    \n",
        "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
        "    \n",
        "    # ================== Validation ======================\n",
        "    \n",
        "    summary = sess.run(fetches=merged_summary, feed_dict={X:x_val, Y:y_val})\n",
        "    validation_writer.add_summary(summary, epoch)\n",
        "\n",
        "print('Done training!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGCe51pHPXde",
        "outputId": "1d899a80-6949-4c87-a933-065c076e0345"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 \t| Training Accuracy = 0.2460000067949295\n",
            "Epoch 1 \t| Training Accuracy = 0.3720000088214874\n",
            "Epoch 2 \t| Training Accuracy = 0.45500001311302185\n",
            "Epoch 3 \t| Training Accuracy = 0.5429999828338623\n",
            "Epoch 4 \t| Training Accuracy = 0.6039999723434448\n",
            "Done training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a Prediction"
      ],
      "metadata": {
        "id": "vNxWPbJAPjOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/test_img.png')\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "X3Ovcp7SPe-b",
        "outputId": "2074ed66-6f2b-4613-c4cd-ddd74d3a8642"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28 at 0x7FBACEBFFB10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bw = img.convert('L')"
      ],
      "metadata": {
        "id": "8xeRue7CQFuw"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = np.invert(bw)"
      ],
      "metadata": {
        "id": "02JfjjM8QFrI"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeXXDLcdQFnx",
        "outputId": "3f708429-e4e1-40c1-c259-33e49279a62d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = img_array.ravel()"
      ],
      "metadata": {
        "id": "25x6KbbPQLOF"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-cMHlB3QNnT",
        "outputId": "3a0752b6-b9c3-427e-be83-d1cd778a66a8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})"
      ],
      "metadata": {
        "id": "GI_hk2_zQQCI"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Prediction for test image is {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq0ZFRHSQSFc",
        "outputId": "89d8e806-3ac2-45c1-f404-d18475c5f888"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for test image is [2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and Evaluation"
      ],
      "metadata": {
        "id": "mr_mKvS1QYK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1= x_test[:10]\n",
        "y_test1= y_test[:10] "
      ],
      "metadata": {
        "id": "cs2XhCKvR9UG"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test1, Y:y_test1})\n",
        "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "zMjqHyaRQUSh",
        "outputId": "fce47d81-65e0-4c69-a511-ec0dc87051a6"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-560691b312bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy on test set is {test_accuracy:0.2%}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1163\u001b[0m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[1;32m   1164\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1165\u001b[0;31m                 \u001b[0;34mf'Cannot feed value of shape {str(np_val.shape)} for Tensor '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;34mf'{subfeed_t.name}, which has shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 f'{str(subfeed_t.get_shape())}')\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (10,) for Tensor Placeholder_6:0, which has shape (?, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reset for the Next Run"
      ],
      "metadata": {
        "id": "5LfKHfaOSYFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_writer.close()\n",
        "validation_writer.close()\n",
        "sess.close()\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "3qJxRxnIQbMX"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for 1st Part of Module"
      ],
      "metadata": {
        "id": "4poaWDdlSsiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('hidden_1'):\n",
        "\n",
        "    initial_w1 = tf.random.truncated_normal(shape=[TOTAL_INPUTS, n_hidden1], stddev=0.1, seed=42)\n",
        "    w1 = tf.Variable(initial_value=initial_w1, name='w1')\n",
        "\n",
        "    initial_b1 = tf.constant(value=0.0, shape=[n_hidden1])\n",
        "    b1 = tf.Variable(initial_value=initial_b1, name='b1')\n",
        "\n",
        "    layer1_in = tf.matmul(X, w1) + b1\n",
        "\n",
        "    layer1_out = tf.nn.relu(layer1_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "vHJod-3ZSsIj",
        "outputId": "bbdb72d7-7732-4497-d4d1-6761653cc5c2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-018b1ede4fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_b1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlayer1_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlayer1_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   6353\u001b[0m     raise ValueError(\n\u001b[1;32m   6354\u001b[0m         \u001b[0;34m\"%s must be from the same graph as %s (graphs are %s and %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6355\u001b[0;31m         (item, original_item, graph, original_graph))\n\u001b[0m\u001b[1;32m   6356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor(\"hidden_1_2/w1/Read/ReadVariableOp:0\", shape=(784, 512), dtype=float32) must be from the same graph as Tensor(\"Placeholder_5:0\", shape=(?, 784), dtype=float32) (graphs are <tensorflow.python.framework.ops.Graph object at 0x7fba87267450> and <tensorflow.python.framework.ops.Graph object at 0x7fb9f8125610>)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QfZtIj38SbgC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}